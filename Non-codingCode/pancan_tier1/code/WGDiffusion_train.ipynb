{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"zwaVU8Sjm2Tc"},"outputs":[],"source":["import argparse\n","import sys\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","import joblib\n","import numpy as np\n","import pandas as pd\n","import xgboost as xgb\n","from scipy.stats import fisher_exact\n","from scipy import stats\n","from sklearn import preprocessing\n","from sklearn.metrics import auc\n","from sklearn.metrics import precision_recall_curve,roc_curve,average_precision_score\n","from sklearn.preprocessing import MinMaxScaler,StandardScaler,RobustScaler,MaxAbsScaler\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn import neighbors\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","import matplotlib.pyplot as plt\n","#from deepforest import CascadeForestClassifier\n","from sklearn.neural_network import MLPClassifier\n","from statsmodels.distributions.empirical_distribution import ECDF\n","from statsmodels.stats.multitest import multipletests\n","import warnings\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import math\n","from math import sqrt\n","import re\n","import os\n","import random\n","import shap\n","\n","warnings.filterwarnings('ignore')\n","seed = 0\n","random.seed(seed)\n","torch.manual_seed(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.deterministic = True\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","#找roc的最优阈值\n","def Find_Optimal_Cutoff(TPR, FPR, threshold):\n","    y = TPR - FPR\n","    Youden_index = np.argmax(y)  # Only the first occurrence is returned.\n","    optimal_threshold = threshold[Youden_index]\n","    point = [FPR[Youden_index], TPR[Youden_index]]\n","    return optimal_threshold, point\n","\n","def fisher_ex(a, b, c, d):\n","    _, pvalue = fisher_exact([[a, b], [c, d]], 'greater')\n","    if pvalue < 1e-256:\n","        pvalue = 1e-256\n","    #p1 = -math.log10(pvalue)\n","    return pvalue\n","\n","def build_set(all_list):\n","  pos_ids_noncds = []\n","  rna_ids = []\n","  neg_ids_noncds = []\n","  test_ids_ex = []\n","  tjumirna_list = []\n","\n","  df_pos_noncds = pd.read_csv(r'/content/drive/MyDrive/fulingya/Target/data/noncds_2.2.csv',sep=',')\n","  pos_ids_noncds = df_pos_noncds['geneid'].values.tolist()\n","  pos_ids = list(set(pos_ids_noncds))\n","  excludes_ids = pos_ids\n","  df_all_list = pd.DataFrame(all_list)\n","  df_all_list.columns = ['id']\n","  df_ffu = df_all_list[~df_all_list['id'].isin(excludes_ids)]\n","  all_list_ffu = df_ffu['id'].values.tolist()\n","  for id in all_list_ffu:\n","    tmps_ffu = re.split('::', id)\n","    reg_ffu = tmps_ffu[0]\n","    reg_ffu1 = tmps_ffu[1]\n","    if 'tjumirna' in reg_ffu1:\n","      tjumirna_list.append(id)\n","    if 'cds' not in reg_ffu and 'tjumirna' not in reg_ffu1:\n","      neg_ids_noncds.append(id) #非编码区其他负样本基因\n","  df_neg_ids_noncds = pd.DataFrame(neg_ids_noncds)\n","  df_fu = df_neg_ids_noncds.sample(n=len(pos_ids)*10,random_state=0,replace = False)\n","  neg_ids = df_fu[0].values.tolist()\n","\n","  for id in all_list:\n","    tmps = re.split('::', id)\n","    gene = tmps[2]\n","    reg = tmps[0]\n","    reg1 = tmps[1]\n","    if 'cds' in reg:\n","      test_ids_ex.append(id)\n","  test_ids = list(set(all_list)-set(test_ids_ex)-set(tjumirna_list))\n","  pos_ids.sort()\n","  neg_ids.sort()\n","  test_ids.sort()\n","  print(len(pos_ids))\n","  print(len(neg_ids))\n","  #print(len(tjumirna_list))\n","  print(len(test_ids))\n","  return pos_ids, neg_ids, test_ids\n","\n","def file2data(cancer_type, train_pos, train_neg, test_ids):\n","    mode_all = ['all', 'mut2', 'cadd', 'css']\n","    tumors_file = '/content/drive/MyDrive/fulingya/MDriver/tumors.txt'\n","    tumors_set = {'Pancan': 'Pancan'}\n","    for line in open(tumors_file, 'rt'):\n","        txt = line.rstrip().split('\\t')\n","        tumors_set[txt[0]] = txt[1]\n","    X_train = []\n","    X_test = []\n","    X = []\n","    for mode in mode_all:\n","      if mode != 'mut2':\n","        fea_one = '/content/drive/MyDrive/fulingya/MDriver/%s/%s.fea' % (tumors_set[cancer_type], mode)\n","        df_one = pd.read_csv(fea_one, header=0, index_col=0, sep='\\t')\n","        #训练数据X\n","        mat_train_pos = df_one.loc[train_pos, ::].values.astype(float)\n","        mat_train_neg = df_one.loc[train_neg, ::].values.astype(float)\n","        X_train.append(np.concatenate([mat_train_pos, mat_train_neg]))\n","\n","        #测试数据X\n","        mat_test = df_one.loc[test_ids, ::].values.astype(float)\n","        X_test.append(mat_test)\n","      if mode == 'mut2':\n","        fea_one = '/content/drive/MyDrive/fulingya/MDriver/%s/%s.fea' % (tumors_set[cancer_type], mode)\n","        df_one = pd.read_csv(fea_one, header=0, index_col=0, sep='\\t')\n","        fea_sublist=['AAA_ref','AAC_ref','AAG_ref','AAT_ref','ACA_ref','ACC_ref','ACG_ref','ACT_ref','AGA_ref','AGC_ref',\n","                      'AGG_ref','ATA_ref','ATC_ref','ATG_ref','CAA_ref','CAC_ref','CAG_ref','CCA_ref','CCC_ref',\n","                      'CCG_ref','CGA_ref','CGC_ref','CTA_ref','CTC_ref','GAA_ref','GAC_ref','GCA_ref','GCC_ref',\n","                      'GGA_ref','GTA_ref','TAA_ref','TCA_ref']\n","        mat_train_pos = df_one.loc[train_pos, fea_sublist].values.astype(float)\n","        mat_train_neg = df_one.loc[train_neg, fea_sublist].values.astype(float)\n","        X_train.append(np.concatenate([mat_train_pos, mat_train_neg]))\n","        #测试数据X\n","        mat_test = df_one.loc[test_ids, fea_sublist].values.astype(float)\n","        X_test.append(mat_test)\n","\n","    X_train=np.concatenate([X_train[0],X_train[1],X_train[2],X_train[3]],axis=1)\n","    Y_train = np.concatenate([np.ones((len(train_pos))), np.zeros((len(train_neg)))])\n","\n","    X_test=np.concatenate([X_test[0],X_test[1],X_test[2],X_test[3]],axis=1)\n","    cla_X_train=pd.DataFrame(X_train)\n","    cla_X_train['class']=Y_train\n","    geneid=np.concatenate([train_pos,train_neg])\n","    cla_X_train['geneid']=geneid\n","    return X_train, Y_train, X_test, cla_X_train\n","\n","def fit_cv(Xs, y,cla_X_train, k,a,b,c,d, b_plot=False, method='0'):\n","  z = 0\n","  n = Xs.shape[0]\n","  tprs = []\n","  p = []\n","  x1_all = []\n","  x2_all = []\n","  mean_fpr = np.linspace(0, 1, 100)\n","  roc_auc = 0\n","  assignments = np.array((n // k + 1) * list(range(1, k + 1)))\n","  assignments = assignments[:n]\n","  mean_tpr = 0.0\n","  mean_fpr = np.linspace(0, 1, 100)\n","  all_tpr = []\n","  all_roc = []\n","  pr=[]\n","  for i in range(1, k + 1):\n","    ix = assignments == i\n","    y_test = y[ix]\n","    y_train = y[~ix]\n","    X_train = Xs[~ix, :]\n","    X_test = Xs[ix, :]\n","\n","    #利用扩散模型实现数据扩增\n","    #print(type(X_train))\n","    dataset = torch.Tensor(X_train).float()\n","    #确定超参数的值\n","    num_steps = 90 #98\n","    #制定每一步的beta\n","    betas = torch.linspace(-6,6,num_steps)\n","    betas = torch.sigmoid(betas)*(0.5e-2 - 1e-5)+1e-5\n","    #计算alpha、alpha_prod、alpha_prod_previous、alpha_bar_sqrt等变量的值\n","    alphas = 1-betas\n","    alphas_prod = torch.cumprod(alphas,0)\n","    alphas_prod_p = torch.cat([torch.tensor([1]).float(),alphas_prod[:-1]],0)\n","    alphas_bar_sqrt = torch.sqrt(alphas_prod)\n","    one_minus_alphas_bar_log = torch.log(1 - alphas_prod)\n","    one_minus_alphas_bar_sqrt = torch.sqrt(1 - alphas_prod)\n","    assert alphas.shape==alphas_prod.shape==alphas_prod_p.shape==\\\n","    alphas_bar_sqrt.shape==one_minus_alphas_bar_log.shape\\\n","    ==one_minus_alphas_bar_sqrt.shape\n","    #print(\"all the same shape\",betas.shape)\n","    #确定扩散过程任意时刻的采样值 可以基于x[0]得到任意时刻t的x[t]\n","    def q_x(x_0,t):\n","      noise = torch.randn_like(x_0)\n","      alphas_t = alphas_bar_sqrt[t]\n","      alphas_1_m_t = one_minus_alphas_bar_sqrt[t]\n","      return (alphas_t * x_0 + alphas_1_m_t * noise) #在x[0]的基础上添加噪声\n","\n","    #编写拟合逆扩散过程高斯分布的模型\n","    class MLPDiffusion(nn.Module):\n","      def __init__(self, n_steps, size, num_units=182): #182\n","        super(MLPDiffusion, self).__init__()\n","        self.res1 = ResnetBlock(size, num_units)\n","        self.res2 = ResnetBlock(num_units, num_units)\n","        # self.attn = MultiHeadSelfAttention(size, num_units, num_units)\n","        self.emb = nn.Embedding(n_steps, num_units)\n","        self.linear = nn.Linear(num_units, size)\n","      def forward(self, x, t):\n","        x = self.res1(x)\n","        for i in range(2):\n","          x = self.res2(x)\n","          emb_t = self.emb(t)\n","          x += emb_t\n","          x = F.relu(x)\n","        y = self.linear(x)\n","        return y, x\n","\n","    class ResnetBlock(nn.Module):\n","      def __init__(self, dim_in, dim_out):\n","        super().__init__()\n","        self.block1 = Block(dim_in, dim_out)\n","        self.block2 = Block(dim_out, dim_out)\n","        # self.attn = MultiHeadSelfAttention(dim_in, dim_out, dim_out)\n","        self.linear = nn.Linear(dim_in, dim_out)\n","\n","      def forward(self, x):\n","        h = self.block1(x)\n","        h = self.block2(h)\n","        return h + self.linear(x)\n","\n","    # class MultiHeadSelfAttention(nn.Module):\n","    #   dim_in: int  # input dimension\n","    #   dim_k: int  # key and query dimension\n","    #   dim_v: int  # value dimension\n","    #   num_heads: int  # number of heads, for each head, dim_* = dim_* // num_heads\n","\n","    #   def __init__(self, dim_in, dim_k, dim_v, num_heads=2):\n","    #     super(MultiHeadSelfAttention, self).__init__()\n","    #     assert dim_k % num_heads == 0 and dim_v % num_heads == 0, \"dim_k and dim_v must be multiple of num_heads\"\n","    #     self.dim_in = dim_in\n","    #     self.dim_k = dim_k\n","    #     self.dim_v = dim_v\n","    #     self.num_heads = num_heads\n","    #     self.linear_q = nn.Linear(dim_in, dim_k, bias=False)\n","    #     self.linear_k = nn.Linear(dim_in, dim_k, bias=False)\n","    #     self.linear_v = nn.Linear(dim_in, dim_v, bias=False)\n","    #     self._norm_fact = 1 / sqrt(dim_k // num_heads)\n","\n","    #   def forward(self, x):\n","    #     # x: tensor of shape (batch, n, dim_in)\n","    #     batch, dim_in = x.shape\n","    #     assert dim_in == self.dim_in\n","\n","    #     nh = self.num_heads  # 2\n","    #     dk = self.dim_k // nh  # dim_k of each head 1\n","    #     dv = self.dim_v // nh  # dim_v of each head 1\n","\n","    #     q = self.linear_q(x.reshape(batch, dim_in)).reshape(batch, nh, dk)  # (batch, nh, n, dk) 5.reshape(16,5,2)\n","    #     k = self.linear_k(x.reshape(batch, dim_in)).reshape(batch, nh, dk)  # (batch, nh, n, dk)\n","    #     v = self.linear_v(x.reshape(batch, dim_in)).reshape(batch, nh, dv)  # (batch, nh, n, dv)\n","\n","    #     dist = torch.matmul(q, k.transpose(1, 2)) * self._norm_fact  # batch, nh, n, n\n","    #     dist = torch.softmax(dist, dim=-1)  # batch, nh, n, n\n","\n","    #     att = torch.matmul(dist, v)  # batch, nh, n, dv\n","    #     att = att.transpose(1, 2).reshape(batch, self.dim_v)  # batch, n, dim_v\n","    #     return att\n","\n","    class Block(nn.Module):\n","      def __init__(self, dim_in, dim_out):\n","        super().__init__()\n","        self.linear = nn.Linear(dim_in, dim_out)\n","        # self.norm = nn.LayerNorm(dim_out)\n","        self.act = nn.GELU()\n","\n","      def forward(self, x):\n","        x = self.linear(x)\n","        # x = self.norm(x)\n","        x = self.act(x)\n","        return x\n","\n","    #编写训练的误差函数\n","    def diffusion_loss_fn(model,x_0,alphas_bar_sqrt,one_minus_alphas_bar_sqrt,n_steps):\n","      #对任意时刻t进行采样计算loss\n","      batch_size = x_0.shape[0]\n","      #对一个batchsize样本生成随机的时刻t\n","      t = torch.randint(0,n_steps,size=(batch_size//2,))\n","      t = torch.cat([t,n_steps-1-t],dim=0)\n","      t = t.unsqueeze(-1)\n","      #x0的系数\n","      a = alphas_bar_sqrt[t]\n","      #eps的系数\n","      aml = one_minus_alphas_bar_sqrt[t]\n","      #生成随机噪音eps\n","      e = torch.randn_like(x_0)\n","      #构造模型的输入\n","      x = x_0*a+e*aml\n","      #送入模型，得到t时刻的随机噪声预测值\n","      output = model(x,t.squeeze(-1))\n","      #与真实噪声一起计算误差，求平均值\n","      output = output[0]\n","      return (e - output).square().mean()\n","\n","    #编写逆扩散采样函数\n","    def p_sample_loop(model,shape,n_steps,betas,one_minus_alphas_bar_sqrt):\n","      #从x[T]恢复x[T-1]、x[T-2]|...x[0]\n","      cur_x = torch.randn(shape)\n","      x_seq = [cur_x]\n","      for i in reversed(range(n_steps)):\n","          cur_x = p_sample(model,cur_x,i,betas,one_minus_alphas_bar_sqrt)\n","          x_seq.append(cur_x)\n","      return x_seq\n","\n","    def p_sample(model,x,t,betas,one_minus_alphas_bar_sqrt):\n","      #从x[T]采样t时刻的重构值\n","      t = torch.tensor([t])\n","      coeff = betas[t] / one_minus_alphas_bar_sqrt[t]\n","      eps_theta = model(x,t)[0]\n","      mean = (1/(1-betas[t]).sqrt())*(x-(coeff*eps_theta))\n","      z = torch.randn_like(x)\n","      sigma_t = betas[t].sqrt()\n","      sample = mean + sigma_t * z\n","      return (sample)\n","\n","    #开始训练模型，打印loss及中间重构效果\n","    print('Training model...')\n","    batch_size = 2 #2\n","    dataloader = torch.utils.data.DataLoader(dataset,batch_size=batch_size,shuffle=True)\n","    num_epoch = 20\n","    model = MLPDiffusion(num_steps,dataset.shape[1]) #输入是x和step\n","    optimizer = torch.optim.Adam(model.parameters(),lr=0.005) #0.00005,0.0051\n","    for t in range(num_epoch):\n","      for idx,batch_x in enumerate(dataloader):\n","        loss = diffusion_loss_fn(model,batch_x,alphas_bar_sqrt,one_minus_alphas_bar_sqrt,num_steps)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(),1.)\n","        optimizer.step()\n","      #if(t%2==0):\n","        #print(loss)\n","      if(t==num_epoch-1):\n","        x_seq = p_sample_loop(model,dataset.shape,num_steps,betas,one_minus_alphas_bar_sqrt)\n","        length = len(x_seq)\n","        X_train_augmentation = x_seq[length - 1]\n","    print(X_train_augmentation.shape,type(X_train_augmentation))\n","    X_train_augmentation = X_train_augmentation.detach().numpy()\n","    y_train_augmentation = y_train\n","\n","    scaler = preprocessing.MinMaxScaler()\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","    joblib.dump(scaler, '/content/drive/MyDrive/fulingya/Target/model/minmax1.scaler')\n","    xtext = ix.nonzero()[0].tolist()\n","    df0 = cla_X_train.iloc[xtext,:]\n","    #print(df0.shape) (410, 84)或者(409, 84) 跟测试集的样本量一样\n","\n","    if method == 'SVM':\n","      model = SVC(probability=True)\n","      model.fit(X_train, y_train)\n","      probas_ = model.predict_proba(X_test)[:, 1]\n","      fpr, tpr, thresholds = roc_curve(y_test, probas_)\n","      # 记录最优门限\n","      roc_auc_1 = auc(fpr, tpr)\n","      print('准确率：{}'.format(roc_auc_1))\n","      pr1=average_precision_score(y_test, probas_)\n","      pr.append(pr1) #准备求平均的auprc\n","      optimal_th, optimal_point = Find_Optimal_Cutoff(TPR=tpr, FPR=fpr, threshold=thresholds)\n","      print('门限：{}'.format(optimal_th))\n","\n","      if roc_auc_1 > z: #准确率最大时，对应的门限值\n","        z = roc_auc_1\n","        m = optimal_th\n","        #joblib.dump(model, '/content/drive/MyDrive/fulingya/Target/model/SVM_pre_druggable.pkl')\n","      del model\n","\n","    if method == 'KNN':\n","      model = neighbors.KNeighborsRegressor()\n","      # print('X_train.shape>>>',X_train.shape)\n","      # print('X_test.shape>>>',X_test.shape)\n","      model.fit(X_train, y_train)\n","      probas_ = model.predict(X_test)\n","      fpr, tpr, thresholds = roc_curve(y_test, probas_)\n","      # 记录最优门限\n","      roc_auc_1 = auc(fpr, tpr)\n","      print('准确率：{}'.format(roc_auc_1))\n","      pr1=average_precision_score(y_test, probas_)\n","      pr.append(pr1) #准备求平均的auprc\n","      optimal_th, optimal_point = Find_Optimal_Cutoff(TPR=tpr, FPR=fpr, threshold=thresholds)\n","      print('门限：{}'.format(optimal_th))\n","\n","      if roc_auc_1 > z: #准确率最大时，对应的门限值\n","        z = roc_auc_1\n","        m = optimal_th\n","        #joblib.dump(model, '/content/drive/MyDrive/fulingya/Target/model/SVM_pre_druggable.pkl')\n","      del model\n","\n","    if method == 'LR':\n","      model = LogisticRegression()\n","      model.fit(X_train, y_train)\n","      probas_ = model.predict_proba(X_test)[:, 1]\n","      fpr, tpr, thresholds = roc_curve(y_test, probas_)\n","      # 记录最优门限\n","      roc_auc_1 = auc(fpr, tpr)\n","      print('准确率：{}'.format(roc_auc_1))\n","      pr1=average_precision_score(y_test, probas_)\n","      pr.append(pr1) #准备求平均的auprc\n","      optimal_th, optimal_point = Find_Optimal_Cutoff(TPR=tpr, FPR=fpr, threshold=thresholds)\n","      print('门限：{}'.format(optimal_th))\n","\n","      if roc_auc_1 > z: #准确率最大时，对应的门限值\n","        z = roc_auc_1\n","        m = optimal_th\n","        #joblib.dump(model, '/content/drive/MyDrive/fulingya/Target/model/LR_pre_druggable.pkl')\n","      del model\n","\n","    if method == 'MLP':\n","      model = MLPClassifier()#hidden_layer_sizes=[3], random_state=5,batch_size=78, max_iter=1000\n","      model.fit(X_train, y_train)\n","      probas_ = model.predict_proba(X_test)[:, 1]\n","\n","      fpr, tpr, thresholds = roc_curve(y_test, probas_)\n","      # 记录最优门限\n","      roc_auc_1 = auc(fpr, tpr)\n","      print('准确率：{}'.format(roc_auc_1))\n","      pr1=average_precision_score(y_test, probas_)\n","      pr.append(pr1) #准备求平均的auprc\n","      optimal_th, optimal_point = Find_Optimal_Cutoff(TPR=tpr, FPR=fpr, threshold=thresholds)\n","      print('门限：{}'.format(optimal_th))\n","\n","      if roc_auc_1 > z: #准确率最大时，对应的门限值\n","        z = roc_auc_1\n","        m = optimal_th\n","        #joblib.dump(model, '/content/drive/MyDrive/fulingya/Target/model/MLP_pre_druggable.pkl')\n","      del model\n","\n","    if method == 'RF':\n","      model = RandomForestClassifier() #n_estimators=30,random_state=0\n","      X_train=pd.DataFrame(X_train)\n","      y_train=pd.DataFrame(y_train)\n","      model.fit(X_train, y_train)\n","      probas_ = model.predict_proba(X_test)[:, 1]\n","      fpr, tpr, thresholds = roc_curve(y_test, probas_)\n","      # 记录最优门限\n","      roc_auc_1 = auc(fpr, tpr)\n","      print('准确率：{}'.format(roc_auc_1))\n","      pr1=average_precision_score(y_test, probas_)\n","      pr.append(pr1) #准备求平均的auprc\n","      optimal_th, optimal_point = Find_Optimal_Cutoff(TPR=tpr, FPR=fpr, threshold=thresholds)\n","      print('门限：{}'.format(optimal_th))\n","      if roc_auc_1 > z: #准确率最大时，对应的门限值\n","        z = roc_auc_1\n","        m = optimal_th\n","        #joblib.dump(model, '/content/drive/MyDrive/fulingya/Target/model/RF_pre_druggable.pkl')\n","      del model\n","\n","\n","    if method == 'XGB':\n","      model=xgb.XGBClassifier(random_state=0)\n","      scaler=joblib.load('/content/drive/MyDrive/fulingya/Target/model/minmax1.scaler')\n","      X_train_augmentation = scaler.fit_transform(X_train_augmentation)\n","      X_train_new=np.concatenate([X_train, X_train_augmentation],axis=0)\n","      y_train_new=np.concatenate([y_train, y_train_augmentation],axis=0)\n","      X_train_new = pd.DataFrame(X_train_new)\n","      # X_train_new.fillna(method = 'ffill', inplace = True)\n","      X_train_new = np.array(X_train_new)\n","      model.fit(X_train_new, y_train_new)\n","\n","\n","      #model.fit(X_train, y_train)\n","      probas_ = model.predict_proba(X_test)[:, 1]\n","      fpr, tpr, thresholds = roc_curve(y_test, probas_)\n","      # 记录最优门限\n","      roc_auc_1 = auc(fpr, tpr)\n","      print('准确率：{}'.format(roc_auc_1))\n","      pr1 = average_precision_score(y_test, probas_)\n","      pr.append(pr1) #准备求平均的auprc\n","      optimal_th, optimal_point = Find_Optimal_Cutoff(TPR=tpr, FPR=fpr, threshold=thresholds)\n","      print('门限：{}'.format(optimal_th))\n","\n","      if roc_auc_1 > z: #准确率最大时，对应的门限值\n","        z = roc_auc_1\n","        m = optimal_th\n","        joblib.dump(model, '/content/drive/MyDrive/fulingya/Target/model/WGDiffusion_train.pkl')\n","      del model\n","\n","    for i in probas_[y_test==0]:\n","      x1_all.append(i)\n","    for i in probas_[y_test==1]:\n","      x2_all.append(i)\n","    tprs.append(np.interp(mean_fpr, fpr, tpr))\n","    tprs[-1][0] = 0.0\n","    roc_auc = auc(fpr, tpr)\n","\n","  mean_tpr = np.mean(tprs, axis=0)\n","  mean_tpr[-1] = 1.0\n","\n","  tatistic, pvalue = stats.mannwhitneyu(x1_all, x2_all, use_continuity=True, alternative='two-sided')#秩和检验\n","  mean_auc = auc(mean_fpr, mean_tpr)\n","  print('roc_pvalue: {}'.format(pvalue))\n","  print(\"Mean AUROC (area = %0.4f),p-value = %f\" % (mean_auc,pvalue))\n","  #输出平均auprc\n","  #print(pr)\n","  sum=0\n","  for i in pr:\n","    sum += i\n","  mean_pr=sum/len(pr)\n","  print('mean_auprc : {:.4f}'.format(mean_pr))\n","  plt.plot(fpr, tpr, label='(XGB=%0.4f)' % mean_auc,)\n","  fpr=fpr[None,:]\n","  tpr=tpr[None,:]\n","  dmx_numpy=np.concatenate([fpr, tpr],axis=0)\n","  dmx_pd=pd.DataFrame(dmx_numpy)\n","  #dmx_pd.to_csv(r'/content/drive/MyDrive/fulingya/Target/result/dmx.csv')\n","  return m #返回准确率最高时对应的门限值  作为预测阶段的阈值\n","\n","#预测非编码区可用药基因\n","def predict(X_test,m,test_ids,X_train,train_pos):\n","    scaler=joblib.load('/content/drive/MyDrive/fulingya/Target/model/minmax1.scaler')\n","    X_test = scaler.fit_transform(X_test)\n","    model=joblib.load('/content/drive/MyDrive/fulingya/Target/model/WGDiffusion_train.pkl')\n","    probas_ = model.predict_proba(X_test)[:, 1]\n","\n","\n","\n","    #shap方法分析特征重要性（全局的特征重要性）\n","    test_x = X_test\n","    test_x=pd.DataFrame(test_x)\n","    test_x.columns=['freq_Intron','freq_IGR','freq_RNA','freq_Missense_Mutation','freq_3UTR','freq_lincRNA',\n","              'freq_5Flank','freq_Silent','freq_5UTR','freq_Splice_Site','freq_Nonsense_Mutation',\n","              'freq_De_novo_Start_OutOfFrame','freq_Frame_Shift_Del','freq_In_Frame_Del',\n","              'freq_Frame_Shift_Ins','freq_De_novo_Start_InFrame','freq_Start_Codon_SNP',\n","              'freq_In_Frame_Ins','freq_Nonstop_Mutation','freq_Start_Codon_Del','freq_Stop_Codon_Del',\n","              'freq_Stop_Codon_Ins','freq_Start_Codon_Ins','freq_SNP','freq_DNP','freq_TNP','freq_DEL',\n","              'freq_INS','freq_ONP','sample_count_mean','sample_count_var','gc_mean','gc_var',\n","              'amp_mean','amp_var','amp_freq','del_mean','del_var','del_freq','abs_mean','abs_var','abs_freq',\n","              'exp_mean','exp_var','rep_time','exp_CCLE','AAA_ref','AAC_ref','AAG_ref','AAT_ref','ACA_ref','ACC_ref','ACG_ref','ACT_ref','AGA_ref','AGC_ref',\n","              'AGG_ref','ATA_ref','ATC_ref','ATG_ref','CAA_ref','CAC_ref','CAG_ref','CCA_ref','CCC_ref',\n","              'CCG_ref','CGA_ref','CGC_ref','CTA_ref','CTC_ref','GAA_ref','GAC_ref','GCA_ref','GCC_ref',\n","              'GGA_ref','GTA_ref','TAA_ref','TCA_ref','CADD_mean','CADD_var','CSS_mean','CSS_var']\n","    explainer = shap.Explainer(model)\n","    shap_values = explainer(test_x)  # 传入特征矩阵X，计算SHAP值 返回列表\n","\n","    # 可视化\n","    shap.initjs()\n","    #shap.plots.bar(shap_values, max_display=41)\n","\n","    #print(shap_values.shape) (119434, 82)\n","    #print(shap_values[0].shape) (82,)\n","    #print(type(shap_values)) <class 'shap._explanation.Explanation'>\n","    #print('index>>>',index)\n","    #shap.plots.heatmap(shap_values)\n","\n","    #单基因可解释\n","    i = 106547\n","    print('对应的基因是>>>',test_ids[i])\n","    shap.plots.waterfall(shap_values[i],max_display=70)\n","\n","    for i in range(len(test_ids)):\n","      if 'miR-3158-5p' in test_ids[i]:\n","        print('基因下标是>>>',i)\n","        print('基因是>>>',test_ids[i])\n","        break\n","\n","    # shap.summary_plot(shap_values[0], test_x, plot_type=\"bar\",max_display=10)\n","    # shap_values=np.array(shap_values)\n","    # importance=pd.DataFrame(shap_values,columns=test_x.columns).mean().sort_values(ascending=False)\n","    # print(importance.head(20))\n","\n","def main(argv=sys.argv):\n","    parser = argparse.ArgumentParser(description='cds_pre_noncds')\n","    parser.add_argument(\"-m\", dest='mode', default=\"pred\", help=\"mode\")\n","    parser.add_argument(\"-t\", dest='type', default=\"Pancan\", help=\"cancer type\")\n","    parser.add_argument(\"-o\", dest='out', default=\"/content/drive/MyDrive/fulingya/\", help=\"coding file\")\n","    args = parser.parse_args(args=[])\n","    cancer_type=args.type\n","\n","    df_tmp = pd.read_csv(r'/content/drive/MyDrive/fulingya/MDriver/chr_id.txt', header=0, index_col=3, sep='\\t', usecols=[0, 1, 2, 3])\n","    all_list = df_tmp.index.tolist()\n","    # print(len(all_list)) #146586\n","\n","    train_pos, train_neg, test_ids = build_set(all_list)\n","    X_train, Y_train, X_test, cla_X_train = file2data(args.type, train_pos, train_neg, test_ids)\n","    #将交叉验证部分的训练数据保存为csv文件\n","    train_geneid = np.concatenate([train_pos, train_neg])\n","    df_train_geneid = pd.DataFrame(train_geneid)\n","    df_train_geneid.columns=['geneid']\n","    df_X_train = pd.DataFrame(X_train)\n","    df_Y_train = pd.DataFrame(Y_train)\n","    df_Y_train.columns = ['label']\n","    feature_train = pd.concat([df_train_geneid, df_X_train, df_Y_train], axis=1)\n","    feature_train.columns=['geneid','freq_Intron','freq_IGR','freq_RNA','freq_Missense_Mutation','freq_3UTR','freq_lincRNA',\n","              'freq_5Flank','freq_Silent','freq_5UTR','freq_Splice_Site','freq_Nonsense_Mutation',\n","              'freq_De_novo_Start_OutOfFrame','freq_Frame_Shift_Del','freq_In_Frame_Del',\n","              'freq_Frame_Shift_Ins','freq_De_novo_Start_InFrame','freq_Start_Codon_SNP',\n","              'freq_In_Frame_Ins','freq_Nonstop_Mutation','freq_Start_Codon_Del','freq_Stop_Codon_Del',\n","              'freq_Stop_Codon_Ins','freq_Start_Codon_Ins','freq_SNP','freq_DNP','freq_TNP','freq_DEL',\n","              'freq_INS','freq_ONP','sample_count_mean','sample_count_var','gc_mean','gc_var',\n","              'amp_mean','amp_var','amp_freq','del_mean','del_var','del_freq','abs_mean','abs_var','abs_freq',\n","              'exp_mean','exp_var','rep_time','exp_CCLE','AAA_ref','AAC_ref','AAG_ref','AAT_ref','ACA_ref','ACC_ref','ACG_ref','ACT_ref','AGA_ref','AGC_ref',\n","              'AGG_ref','ATA_ref','ATC_ref','ATG_ref','CAA_ref','CAC_ref','CAG_ref','CCA_ref','CCC_ref',\n","              'CCG_ref','CGA_ref','CGC_ref','CTA_ref','CTC_ref','GAA_ref','GAC_ref','GCA_ref','GCC_ref',\n","              'GGA_ref','GTA_ref','TAA_ref','TCA_ref','CADD_mean','CADD_var','CSS_mean','CSS_var','label']\n","    print(feature_train.shape)\n","    feature_train.to_csv(r'/content/drive/MyDrive/fulingya/Target/data/XGB_pre_CV.csv', index=False)\n","\n","    m = fit_cv(X_train,Y_train,cla_X_train,5,0,0,0,0, method='XGB')\n","    # # print('m_真实>>',m)\n","    # 解释\n","    # if args.mode == 'pred':\n","    #    predict(X_test,m,test_ids,X_train,train_pos)\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","source":[],"metadata":{"id":"_V15EQWuih1p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Unbrwjxyih4H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Ums5kb0mih5l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zDJhOuc2ih7v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ohHGFf-yih94"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kaybGtajiiAH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"B1RDJAs1iiC7"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}