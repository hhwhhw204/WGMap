{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bqmBCbL8NVVQ"},"outputs":[],"source":["import argparse\n","import sys\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","import joblib\n","import numpy as np\n","import pandas as pd\n","import xgboost as xgb\n","from scipy.stats import fisher_exact\n","from scipy import stats\n","from sklearn import preprocessing\n","from sklearn.metrics import auc\n","from sklearn.metrics import precision_recall_curve,roc_curve,average_precision_score\n","from sklearn.preprocessing import MinMaxScaler,StandardScaler,RobustScaler,MaxAbsScaler\n","from sklearn.semi_supervised import SelfTrainingClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","import matplotlib.pyplot as plt\n","# from deepforest import CascadeForestClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.linear_model import LogisticRegression\n","import warnings\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import math\n","from math import sqrt\n","import re\n","import os\n","import random\n","import shap\n","\n","warnings.filterwarnings('ignore')\n","seed = 0\n","random.seed(seed)\n","torch.manual_seed(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.deterministic = True\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","#找roc的最优阈值\n","def Find_Optimal_Cutoff(TPR, FPR, threshold):\n","    y = TPR - FPR\n","    Youden_index = np.argmax(y)  # Only the first occurrence is returned.\n","    optimal_threshold = threshold[Youden_index]\n","    point = [FPR[Youden_index], TPR[Youden_index]]\n","    return optimal_threshold, point\n","\n","def fisher_ex(a, b, c, d):\n","    _, pvalue = fisher_exact([[a, b], [c, d]], 'greater')\n","    if pvalue < 1e-256:\n","        pvalue = 1e-256\n","    #p1 = -math.log10(pvalue)\n","    return pvalue\n","\n","def build_set(cancer_type, all_list):\n","  pos_ids_noncds = []\n","  rna_ids = []\n","  neg_ids_noncds = []\n","  test_ids_ex = []\n","  tjumirna_list = []\n","  pos_path = '/content/drive/MyDrive/fulingya/each_cancer/eachcancer/data1/%s.csv' % cancer_type\n","  df_pos_noncds = pd.read_csv(pos_path, sep=',')\n","  pos_ids_noncds = df_pos_noncds['geneid'].values.tolist()\n","  pos_ids = list(set(pos_ids_noncds))\n","  #随机选择负样本 前提是排除可能的正样本\n","  tumor_list = ['Breast-AdenoCA', 'Eso-AdenoCA', 'Liver-HCC', 'Ovary-AdenoCA',\n","          'Stomach-AdenoCA', 'Prost-AdenoCA', 'Head-SCC']\n","  excludes = []\n","  for i in tumor_list:\n","    if i != cancer_type:\n","      path = '/content/drive/MyDrive/fulingya/each_cancer/eachcancer/data1/%s.csv' % i\n","      exclude = pd.read_csv(path, sep=',')\n","      exclude = exclude['geneid'].values.tolist()\n","      for j in exclude:\n","        excludes.append(j)\n","  #去重\n","  excludes = list(set(excludes))\n","  excludes_ids = pos_ids + excludes\n","  df_all_list = pd.DataFrame(all_list)\n","  df_all_list.columns = ['id']\n","  df_ffu = df_all_list[~df_all_list['id'].isin(excludes_ids)]\n","  all_list_ffu = df_ffu['id'].values.tolist()\n","  for id in all_list_ffu:\n","    tmps_ffu = re.split('::', id)\n","    reg_ffu = tmps_ffu[0]\n","    reg_ffu1 = tmps_ffu[1]\n","    if 'tjumirna' in reg_ffu1:\n","      tjumirna_list.append(id)\n","    if 'cds' not in reg_ffu and 'tjumirna' not in reg_ffu1:# and 'trnascanse' not in reg_ffu1 and 'snornabase' not in reg_ffu1 and 'mitranscriptome' not in reg_ffu1:\n","      neg_ids_noncds.append(id) #非编码区其他负样本基因\n","  df_neg_ids_noncds = pd.DataFrame(neg_ids_noncds)\n","  df_fu = df_neg_ids_noncds.sample(n=len(pos_ids)*10,random_state=3,replace = False)\n","  neg_ids = df_fu[0].values.tolist()\n","\n","  for id in all_list:\n","    tmps = re.split('::', id)\n","    gene = tmps[2]\n","    reg = tmps[0]\n","    reg1 = tmps[1]\n","    if 'cds' in reg:# or 'mitranscriptome' in reg1 or 'trnascanse' in reg1 or 'snornabase' in reg1:\n","      test_ids_ex.append(id)\n","  test_ids = list(set(all_list)-set(test_ids_ex)-set(tjumirna_list))\n","  pos_ids.sort()\n","  neg_ids.sort()\n","  test_ids.sort()\n","  print(len(pos_ids))\n","  print(len(neg_ids))\n","  #print(len(tjumirna_list))\n","  print(len(test_ids))\n","  return pos_ids, neg_ids, test_ids\n","\n","def file2data(cancer_type, train_pos, train_neg, test_ids):\n","    mode_all = ['cadd', 'cna', 'css', 'mut', 'mut2', 'rna']\n","    X_train = []\n","    X_test = []\n","    X = []\n","    for mode in mode_all:\n","      if mode != 'mut2':\n","        fea_one = '/content/drive/MyDrive/fulingya/each_cancer/eachcancer/ECancer_fea/%s/%s.fea' % (cancer_type, mode)\n","        df_one = pd.read_csv(fea_one, header=0, index_col=0, sep='\\t')\n","        #训练数据X\n","        mat_train_pos = df_one.loc[train_pos, ::].values.astype(float)\n","        mat_train_neg = df_one.loc[train_neg, ::].values.astype(float)\n","        X_train.append(np.concatenate([mat_train_pos, mat_train_neg]))\n","\n","        #测试数据X\n","        mat_test = df_one.loc[test_ids, ::].values.astype(float)\n","        X_test.append(mat_test)\n","      if mode == 'mut2':\n","        fea_one = '/content/drive/MyDrive/fulingya/each_cancer/eachcancer/ECancer_fea/%s/%s.fea' % (cancer_type, mode)\n","        df_one = pd.read_csv(fea_one, header=0, index_col=0, sep='\\t')\n","        fea_sublist=['AAA_ref','AAC_ref','AAG_ref','AAT_ref','ACA_ref','ACC_ref','ACG_ref','ACT_ref','AGA_ref','AGC_ref',\n","                      'AGG_ref','ATA_ref','ATC_ref','ATG_ref','CAA_ref','CAC_ref','CAG_ref','CCA_ref','CCC_ref',\n","                      'CCG_ref','CGA_ref','CGC_ref','CTA_ref','CTC_ref','GAA_ref','GAC_ref','GCA_ref','GCC_ref',\n","                      'GGA_ref','GTA_ref','TAA_ref','TCA_ref']\n","        mat_train_pos = df_one.loc[train_pos, fea_sublist].values.astype(float)\n","        mat_train_neg = df_one.loc[train_neg, fea_sublist].values.astype(float)\n","        X_train.append(np.concatenate([mat_train_pos, mat_train_neg]))\n","        #测试数据X\n","        mat_test = df_one.loc[test_ids, fea_sublist].values.astype(float)\n","        X_test.append(mat_test)\n","\n","    X_train=np.concatenate([X_train[0],X_train[1],X_train[2],X_train[3],X_train[4],X_train[5]],axis=1)\n","    Y_train = np.concatenate([np.ones((len(train_pos))), np.zeros((len(train_neg)))])\n","\n","    X_test=np.concatenate([X_test[0],X_test[1],X_test[2],X_test[3],X_test[4],X_test[5]],axis=1)\n","    cla_X_train=pd.DataFrame(X_train)\n","    cla_X_train['class']=Y_train\n","    geneid=np.concatenate([train_pos,train_neg])\n","    cla_X_train['geneid']=geneid\n","    return X_train, Y_train, X_test, cla_X_train\n","\n","def train(cancer_type, method='0'):\n","  df = pd.read_csv(r'/content/drive/MyDrive/fulingya/each_cancer/eachcancer/result/%s_CV_tra_1.csv' % cancer_type,header = 0,sep=',')\n","  y_train = df['label']\n","  y_train = np.array(y_train)\n","  features = df.drop(['geneid', 'label'], axis=1)\n","  X_train = np.array(features)\n","  df1 = pd.read_csv(r'/content/drive/MyDrive/fulingya/each_cancer/eachcancer/result/%s_CV_val_1.csv' % cancer_type,header = 0,sep=',')\n","  y_test = df1['label']\n","  y_test = np.array(y_test)\n","  features1 = df1.drop(['geneid', 'label'], axis=1)\n","  X_test = np.array(features1)\n","\n","  #利用扩散模型实现数据扩增\n","  #print(type(X_train))\n","  dataset = torch.Tensor(X_train).float()\n","  #确定超参数的值\n","  num_steps = 100\n","  #制定每一步的beta\n","  betas = torch.linspace(-6,6,num_steps)\n","  betas = torch.sigmoid(betas)*(0.5e-2 - 1e-5)+1e-5\n","  #计算alpha、alpha_prod、alpha_prod_previous、alpha_bar_sqrt等变量的值\n","  alphas = 1-betas\n","  alphas_prod = torch.cumprod(alphas,0)\n","  alphas_prod_p = torch.cat([torch.tensor([1]).float(),alphas_prod[:-1]],0)\n","  alphas_bar_sqrt = torch.sqrt(alphas_prod)\n","  one_minus_alphas_bar_log = torch.log(1 - alphas_prod)\n","  one_minus_alphas_bar_sqrt = torch.sqrt(1 - alphas_prod)\n","  assert alphas.shape==alphas_prod.shape==alphas_prod_p.shape==\\\n","  alphas_bar_sqrt.shape==one_minus_alphas_bar_log.shape\\\n","  ==one_minus_alphas_bar_sqrt.shape\n","  #print(\"all the same shape\",betas.shape)\n","  #确定扩散过程任意时刻的采样值 可以基于x[0]得到任意时刻t的x[t]\n","  def q_x(x_0,t):\n","    noise = torch.randn_like(x_0)\n","    alphas_t = alphas_bar_sqrt[t]\n","    alphas_1_m_t = one_minus_alphas_bar_sqrt[t]\n","    return (alphas_t * x_0 + alphas_1_m_t * noise) #在x[0]的基础上添加噪声\n","\n","  #编写拟合逆扩散过程高斯分布的模型\n","  class MLPDiffusion(nn.Module):\n","    def __init__(self, n_steps, size, num_units=100): #172;100\n","      super(MLPDiffusion, self).__init__()\n","      self.res1 = ResnetBlock(size, num_units)\n","      self.res2 = ResnetBlock(num_units, num_units)\n","      self.attn = MultiHeadSelfAttention(size, num_units, num_units)\n","      self.emb = nn.Embedding(n_steps, num_units)\n","      self.linear = nn.Linear(num_units, size)\n","    def forward(self, x, t):\n","      x = self.res1(x)\n","      for i in range(2):\n","        x = self.res2(x)\n","        emb_t = self.emb(t)\n","        x += emb_t\n","        x = F.relu(x)\n","      y = self.linear(x)\n","      return y, x\n","\n","  class ResnetBlock(nn.Module):\n","    def __init__(self, dim_in, dim_out):\n","      super().__init__()\n","      self.block1 = Block(dim_in, dim_out)\n","      self.block2 = Block(dim_out, dim_out)\n","      # self.attn = MultiHeadSelfAttention(dim_in, dim_out, dim_out)\n","      self.linear = nn.Linear(dim_in, dim_out)\n","\n","    def forward(self, x):\n","      h = self.block1(x)\n","      h = self.block2(h)\n","      return h + self.linear(x)\n","\n","  class MultiHeadSelfAttention(nn.Module):\n","    dim_in: int  # input dimension\n","    dim_k: int  # key and query dimension\n","    dim_v: int  # value dimension\n","    num_heads: int  # number of heads, for each head, dim_* = dim_* // num_heads\n","\n","    def __init__(self, dim_in, dim_k, dim_v, num_heads=2):\n","      super(MultiHeadSelfAttention, self).__init__()\n","      assert dim_k % num_heads == 0 and dim_v % num_heads == 0, \"dim_k and dim_v must be multiple of num_heads\"\n","      self.dim_in = dim_in\n","      self.dim_k = dim_k\n","      self.dim_v = dim_v\n","      self.num_heads = num_heads\n","      self.linear_q = nn.Linear(dim_in, dim_k, bias=False)\n","      self.linear_k = nn.Linear(dim_in, dim_k, bias=False)\n","      self.linear_v = nn.Linear(dim_in, dim_v, bias=False)\n","      self._norm_fact = 1 / sqrt(dim_k // num_heads)\n","\n","    def forward(self, x):\n","      # x: tensor of shape (batch, n, dim_in)\n","      batch, dim_in = x.shape\n","      assert dim_in == self.dim_in\n","\n","      nh = self.num_heads  # 2\n","      dk = self.dim_k // nh  # dim_k of each head 1\n","      dv = self.dim_v // nh  # dim_v of each head 1\n","\n","      q = self.linear_q(x.reshape(batch, dim_in)).reshape(batch, nh, dk)  # (batch, nh, n, dk) 5.reshape(16,5,2)\n","      k = self.linear_k(x.reshape(batch, dim_in)).reshape(batch, nh, dk)  # (batch, nh, n, dk)\n","      v = self.linear_v(x.reshape(batch, dim_in)).reshape(batch, nh, dv)  # (batch, nh, n, dv)\n","\n","      dist = torch.matmul(q, k.transpose(1, 2)) * self._norm_fact  # batch, nh, n, n\n","      dist = torch.softmax(dist, dim=-1)  # batch, nh, n, n\n","\n","      att = torch.matmul(dist, v)  # batch, nh, n, dv\n","      att = att.transpose(1, 2).reshape(batch, self.dim_v)  # batch, n, dim_v\n","      return att\n","\n","  class Block(nn.Module):\n","    def __init__(self, dim_in, dim_out):\n","      super().__init__()\n","      self.linear = nn.Linear(dim_in, dim_out)\n","      # self.norm = nn.LayerNorm(dim_out)\n","      self.act = nn.GELU()\n","\n","    def forward(self, x):\n","      x = self.linear(x)\n","      # x = self.norm(x)\n","      x = self.act(x)\n","      return x\n","\n","  #编写训练的误差函数\n","  def diffusion_loss_fn(model,x_0,alphas_bar_sqrt,one_minus_alphas_bar_sqrt,n_steps):\n","    #对任意时刻t进行采样计算loss\n","    batch_size = x_0.shape[0]\n","    #对一个batchsize样本生成随机的时刻t\n","    t = torch.randint(0,n_steps,size=(batch_size//2,))\n","    t = torch.cat([t,n_steps-1-t],dim=0)\n","    t = t.unsqueeze(-1)\n","    #x0的系数\n","    a = alphas_bar_sqrt[t]\n","    #eps的系数\n","    aml = one_minus_alphas_bar_sqrt[t]\n","    #生成随机噪音eps\n","    e = torch.randn_like(x_0)\n","    #构造模型的输入\n","    x = x_0*a+e*aml\n","    #送入模型，得到t时刻的随机噪声预测值\n","    output = model(x,t.squeeze(-1))\n","    #与真实噪声一起计算误差，求平均值\n","    output = output[0]\n","    return (e - output).square().mean()\n","\n","  #编写逆扩散采样函数\n","  def p_sample_loop(model,shape,n_steps,betas,one_minus_alphas_bar_sqrt):\n","    #从x[T]恢复x[T-1]、x[T-2]|...x[0]\n","    cur_x = torch.randn(shape)\n","    x_seq = [cur_x]\n","    for i in reversed(range(n_steps)):\n","        cur_x = p_sample(model,cur_x,i,betas,one_minus_alphas_bar_sqrt)\n","        x_seq.append(cur_x)\n","    return x_seq\n","\n","  def p_sample(model,x,t,betas,one_minus_alphas_bar_sqrt):\n","    #从x[T]采样t时刻的重构值\n","    t = torch.tensor([t])\n","    coeff = betas[t] / one_minus_alphas_bar_sqrt[t]\n","    eps_theta = model(x,t)[0]\n","    mean = (1/(1-betas[t]).sqrt())*(x-(coeff*eps_theta))\n","    z = torch.randn_like(x)\n","    sigma_t = betas[t].sqrt()\n","    sample = mean + sigma_t * z\n","    return (sample)\n","\n","  #开始训练模型，打印loss及中间重构效果\n","  print('Training model...')\n","  batch_size = 2\n","  dataloader = torch.utils.data.DataLoader(dataset,batch_size=batch_size,shuffle=True)\n","  num_epoch = 19 #10\n","  model = MLPDiffusion(num_steps,dataset.shape[1]) #输入是x和step\n","  optimizer = torch.optim.Adam(model.parameters(),lr=0.003) #0.003\n","  for t in range(num_epoch):\n","    loss_list = []\n","    for idx,batch_x in enumerate(dataloader):\n","      loss = diffusion_loss_fn(model,batch_x,alphas_bar_sqrt,one_minus_alphas_bar_sqrt,num_steps)\n","      optimizer.zero_grad()\n","      loss.backward()\n","      torch.nn.utils.clip_grad_norm_(model.parameters(),1.)\n","      optimizer.step()\n","      loss = loss.detach().numpy()\n","      loss_list.append(loss)\n","    if(t==num_epoch-1):\n","      x_seq = p_sample_loop(model,dataset.shape,num_steps,betas,one_minus_alphas_bar_sqrt)\n","      length = len(x_seq)\n","      X_train_augmentation = x_seq[length - 1]\n","  # plt.plot(loss_list,'-^')\n","  # plt.show()\n","  # print(X_train_augmentation.shape,type(X_train_augmentation))\n","  X_train_augmentation = X_train_augmentation.detach().numpy()\n","  y_train_augmentation = y_train\n","  scaler = preprocessing.MinMaxScaler()\n","  X_train = scaler.fit_transform(X_train)\n","  X_test = scaler.transform(X_test)\n","  joblib.dump(scaler, '/content/drive/MyDrive/fulingya/each_cancer/eachcancer/model/%s.xgbscaler_v' % cancer_type)\n","  if method == 'XGB':\n","    model=xgb.XGBClassifier(random_state=0)\n","    scaler=joblib.load('/content/drive/MyDrive/fulingya/each_cancer/eachcancer/model/%s.xgbscaler_v' % cancer_type)\n","    X_train_augmentation = scaler.fit_transform(X_train_augmentation)\n","    #print(X_train_augmentation)\n","    X_train_new=np.concatenate([X_train, X_train_augmentation],axis=0)\n","    y_train_new=np.concatenate([y_train, y_train_augmentation],axis=0)\n","    model.fit(X_train_new, y_train_new)\n","    #model.fit(X_train, y_train)\n","    probas_ = model.predict_proba(X_test)[:, 1]\n","    print('probas_>>>',probas_)\n","    #print('X_test>>>',X_test)\n","    fpr, tpr, thresholds = roc_curve(y_test, probas_)\n","    #print(fpr)\n","    #print(tpr)\n","    # 记录最优门限\n","    roc_auc_1 = auc(fpr, tpr)\n","    print('AUROC：{:.4f}'.format(roc_auc_1))\n","    pr1 = average_precision_score(y_test, probas_)\n","    #print(probas_)\n","    print('AUPRC：{:.4f}'.format(pr1))\n","    optimal_th, optimal_point = Find_Optimal_Cutoff(TPR=tpr, FPR=fpr, threshold=thresholds)\n","    precision, recall, thresholds = precision_recall_curve(y_test, probas_)\n","    thresholds = np.append(thresholds, 1)\n","    # 寻找精确度不低于0.7的阈值\n","    optimal_threshold = thresholds[precision >= 0.8][0]\n","    print('精确度和召回率指标的最优门限：{}'.format(optimal_threshold))\n","    m = optimal_threshold\n","    joblib.dump(model, '/content/drive/MyDrive/fulingya/each_cancer/eachcancer/model/%s_WGDiffusion_predict.pkl' % cancer_type)\n","    del model\n","\n","    x1_all = []\n","    x2_all = []\n","    for i in probas_[y_test==0]:\n","      x1_all.append(i)\n","    for i in probas_[y_test==1]:\n","      x2_all.append(i)\n","\n","    tatistic, pvalue = stats.mannwhitneyu(x1_all, x2_all, use_continuity=True, alternative='two-sided')#秩和检验\n","    print('roc_pvalue: {}'.format(pvalue))\n","  return m\n","\n","#预测非编码区可成药基因\n","def predict(cancer_type,X_test,m,test_ids,X_train,Y_train,train_pos):\n","    scaler=joblib.load('/content/drive/MyDrive/fulingya/each_cancer/eachcancer/model/%s.xgbscaler_v' % cancer_type)\n","    X_test = scaler.fit_transform(X_test)\n","    model=joblib.load('/content/drive/MyDrive/fulingya/each_cancer/eachcancer/model/%s_WGDiffusion_predict.pkl' % cancer_type)\n","    probas_ = model.predict_proba(X_test)[:, 1]\n","\n","    probas_df = pd.DataFrame(probas_)\n","    probas_df.columns = ['score']\n","\n","    # #shap方法分析特征重要性（全局的特征重要性）\n","    # test_x = X_test\n","    # test_x=pd.DataFrame(test_x)\n","    # test_x.columns=['CADD_mean','CADD_var',\n","    #         'amp_mean','amp_var','amp_freq','del_mean','del_var','del_freq','abs_mean','abs_var','abs_freq',\n","    #         'CSS_mean','CSS_var',\n","    #         'freq_Intron','freq_IGR','freq_RNA','freq_Missense_Mutation','freq_3UTR','freq_lincRNA',\n","    #         'freq_5Flank','freq_Silent','freq_5UTR','freq_Splice_Site','freq_Nonsense_Mutation',\n","    #         'freq_De_novo_Start_OutOfFrame','freq_Frame_Shift_Del','freq_In_Frame_Del',\n","    #         'freq_Frame_Shift_Ins','freq_De_novo_Start_InFrame','freq_Start_Codon_SNP',\n","    #         'freq_In_Frame_Ins','freq_Nonstop_Mutation','freq_Start_Codon_Del','freq_Stop_Codon_Del',\n","    #         'freq_Stop_Codon_Ins','freq_Start_Codon_Ins','freq_SNP','freq_DNP','freq_TNP','freq_DEL',\n","    #         'freq_INS','freq_ONP','sample_count_mean','sample_count_var','gc_mean','gc_var',\n","    #         'AAA_ref','AAC_ref','AAG_ref','AAT_ref','ACA_ref','ACC_ref','ACG_ref','ACT_ref','AGA_ref','AGC_ref',\n","    #         'AGG_ref','ATA_ref','ATC_ref','ATG_ref','CAA_ref','CAC_ref','CAG_ref','CCA_ref','CCC_ref',\n","    #         'CCG_ref','CGA_ref','CGC_ref','CTA_ref','CTC_ref','GAA_ref','GAC_ref','GCA_ref','GCC_ref',\n","    #         'GGA_ref','GTA_ref','TAA_ref','TCA_ref',\n","    #         'exp_mean','exp_var','rep_time','exp_CCLE']\n","    # explainer = shap.Explainer(model)\n","    # shap_values = explainer(test_x)  # 传入特征矩阵X，计算SHAP值 返回列表\n","\n","    # # 可视化\n","    # shap.initjs()\n","    # shap.plots.bar(shap_values, max_display=11)\n","\n","    druggable=0\n","    index=[]\n","    probas_list=list(probas_)\n","\n","    for i in range(len(probas_list)):\n","      if probas_list[i]>m:\n","        #print(probas_list[i])\n","        druggable+=1\n","        index.append(i)\n","    enhancers_id=0\n","    cds_id=0\n","    utr3_id=0\n","    utr5_id=0\n","    gcprom_id=0\n","    lncrna_prom_id=0\n","    lncrna_id=0\n","    lncrna_ncrna_id=0\n","    lncrna_ss_id = 0\n","    mirna_id=0\n","    smallrna_id = 0\n","    other_id=0\n","    cds_id_pos=0\n","    ch_ids=0\n","    noncds_id_pos=0\n","    drugable_id=[]\n","    drugable_score=[]\n","    ch_grade = []\n","    for i in index:\n","      drugable_id.append(test_ids[i])\n","      drugable_score.append(probas_list[i])\n","      tmps = re.split('::', test_ids[i])\n","      gene = tmps[2]\n","      reg = tmps[0]\n","      if 'enhancers' in reg:\n","        enhancers_id+=1\n","      if 'gc19_pc.cds' in reg:\n","        cds_id+=1\n","      if 'gc19_pc.3utr' in reg:\n","        utr3_id+=1\n","      if 'gc19_pc.5utr' in reg:\n","        utr5_id+=1\n","      if 'gc19_pc.promCore' in reg:\n","        gcprom_id+=1\n","      if 'lncrna.promCore' in reg:\n","        lncrna_prom_id+=1\n","      if 'lncrna.ncrna' in reg:\n","        lncrna_ncrna_id+=1\n","      if 'lncrna.ss' in reg:\n","        lncrna_ss_id+=1\n","      if 'mirna' in reg:\n","        mirna_id+=1\n","      if 'smallrna' in reg:\n","        smallrna_id+=1\n","      if 'enhancers' not in reg and 'gc19_pc.cds' not in reg and 'gc19_pc.3utr' not in reg and 'gc19_pc.5utr' not in reg and 'gc19_pc.promCore' not in reg and 'lncrna.promCore' not in reg and 'lncrna.ncrna' not in reg:\n","        other_id+=1\n","    #drugable_id.sort()\n","    drugable_id_pd=pd.DataFrame(drugable_id)\n","    drugable_id_pd.columns = ['geneid']\n","    drugable_score_pd=pd.DataFrame(drugable_score)\n","    drugable_score_pd.columns = ['score']\n","    drugable_index_pd=pd.DataFrame(index)\n","    drugable_index_pd.columns = ['index_i']\n","    drugable_id_score=pd.concat([drugable_id_pd,drugable_score_pd,drugable_index_pd],axis=1)\n","    drugable_id_score.sort_values(by=['geneid','score'], ascending=True, inplace=True)\n","    drugable_id_score.to_csv(r'/content/drive/MyDrive/fulingya/each_cancer/eachcancer/result/targetGenes_Hcredible_%s.csv' % cancer_type, index=False)\n","\n","    print(druggable)\n","    print('enhancers({})'.format(enhancers_id))\n","    print('gc19_pc.cds({})'.format(cds_id))\n","    print('gc19_pc.utr3({})'.format(utr3_id))\n","    print('gc19_pc.utr5({})'.format(utr5_id))\n","    print('gc19_pc_prom({})'.format(gcprom_id))\n","    print('mirna({})'.format(mirna_id))\n","    print('smallrna({})'.format(smallrna_id))\n","    print('lncrna_prom({})'.format(lncrna_prom_id))\n","    print('lncrna.ncrna({})'.format(lncrna_ncrna_id))\n","    print('lncrna.ss({})'.format(lncrna_ss_id))\n","\n","def main(argv=sys.argv):\n","    parser = argparse.ArgumentParser(description='eachcancer')\n","    parser.add_argument(\"-m\", dest='mode', default=\"pred\", help=\"mode\")\n","    parser.add_argument(\"-t\", dest='type', default=\"Stomach-AdenoCA\", help=\"cancer type\")\n","    parser.add_argument(\"-o\", dest='out', default=\"/content/drive/MyDrive/fulingya/\", help=\"coding file\")\n","    args = parser.parse_args(args=[])\n","    cancer_type=args.type\n","\n","    df_tmp = pd.read_csv(r'/content/drive/MyDrive/fulingya/MDriver/chr_id.txt', header=0, index_col=3, sep='\\t', usecols=[0, 1, 2, 3])\n","    all_list = df_tmp.index.tolist()\n","\n","    train_pos, train_neg, test_ids = build_set(args.type, all_list)\n","    X_train, Y_train, X_test, cla_X_train = file2data(args.type, train_pos, train_neg, test_ids)\n","    # print(X_train.shape)\n","    # print(Y_train.shape)\n","    # print(X_test.shape)\n","    #将交叉验证部分的训练数据保存为csv文件\n","    train_geneid = np.concatenate([train_pos, train_neg])\n","    df_train_geneid = pd.DataFrame(train_geneid)\n","    df_train_geneid.columns=['geneid']\n","    df_X_train = pd.DataFrame(X_train)\n","    df_Y_train = pd.DataFrame(Y_train)\n","    df_Y_train.columns = ['label']\n","    feature_train = pd.concat([df_train_geneid, df_X_train, df_Y_train], axis=1)\n","    feature_train.columns=['geneid','CADD_mean','CADD_var',\n","            'amp_mean','amp_var','amp_freq','del_mean','del_var','del_freq','abs_mean','abs_var','abs_freq',\n","            'CSS_mean','CSS_var',\n","            'freq_Intron','freq_IGR','freq_RNA','freq_Missense_Mutation','freq_3UTR','freq_lincRNA',\n","            'freq_5Flank','freq_Silent','freq_5UTR','freq_Splice_Site','freq_Nonsense_Mutation',\n","            'freq_De_novo_Start_OutOfFrame','freq_Frame_Shift_Del','freq_In_Frame_Del',\n","            'freq_Frame_Shift_Ins','freq_De_novo_Start_InFrame','freq_Start_Codon_SNP',\n","            'freq_In_Frame_Ins','freq_Nonstop_Mutation','freq_Start_Codon_Del','freq_Stop_Codon_Del',\n","            'freq_Stop_Codon_Ins','freq_Start_Codon_Ins','freq_SNP','freq_DNP','freq_TNP','freq_DEL',\n","            'freq_INS','freq_ONP','sample_count_mean','sample_count_var','gc_mean','gc_var',\n","            'AAA_ref','AAC_ref','AAG_ref','AAT_ref','ACA_ref','ACC_ref','ACG_ref','ACT_ref','AGA_ref','AGC_ref',\n","            'AGG_ref','ATA_ref','ATC_ref','ATG_ref','CAA_ref','CAC_ref','CAG_ref','CCA_ref','CCC_ref',\n","            'CCG_ref','CGA_ref','CGC_ref','CTA_ref','CTC_ref','GAA_ref','GAC_ref','GCA_ref','GCC_ref',\n","            'GGA_ref','GTA_ref','TAA_ref','TCA_ref',\n","            'exp_mean','exp_var','rep_time','exp_CCLE','label']\n","    print(feature_train.shape)\n","    feature_train.to_csv(r'/content/drive/MyDrive/fulingya/each_cancer/eachcancer/result/%s_CV_1.csv' % args.type, index=False)\n","    print(feature_train.shape[0])\n","    length = int(feature_train.shape[0] * 0.7) #0.8\n","    feature_train=feature_train.sample(frac=1.0,random_state=3)#\n","    feature_train_tra=feature_train.iloc[:length]\n","    print(feature_train_tra.shape)\n","    feature_train_tra.to_csv(r'/content/drive/MyDrive/fulingya/each_cancer/eachcancer/result/%s_CV_tra_1.csv' % args.type, index=False)\n","    feature_train_va=feature_train.iloc[length:]\n","    print(feature_train_va.shape)\n","    feature_train_va.to_csv(r'/content/drive/MyDrive/fulingya/each_cancer/eachcancer/result/%s_CV_val_1.csv' % args.type, index=False)\n","\n","    m=train(cancer_type,method = 'XGB')\n","    if args.mode == 'pred':\n","      predict(cancer_type,X_test,m,test_ids,X_train,Y_train,train_pos)\n","\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","source":[],"metadata":{"id":"_o7cAT378pDv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MaM0nJbh8pHP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3Ihm0bnV8pJX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"j75dA-1P8pLZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WkFDESTT8pNu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9Ib3gw5_8pPs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hPrXNa2B8pSB"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}